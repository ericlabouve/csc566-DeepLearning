{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hqpLV-_JSTW1"
   },
   "source": [
    "# Undercomplete autoencoders\n",
    "\n",
    "In this notebook we explore the use of undercomplete autoencoders to compress data and synthesize new data.\n",
    "\n",
    "A autoencoder, in its simplest form, is a neural network that is trained to match its output to its input.  The autoencoder is composed of two parts: an encoder $f$ and a decoder $g$.\n",
    "\n",
    "$$\\mathbf{x}_{out} = g(f(\\mathbf{x}_{in}))$$\n",
    "\n",
    "Here, both $f$ and $g$ will be implemented as multi-layer perceptrons, i.e. neural networks with multiple hidden layers and non-linear activation functions.\n",
    "\n",
    "In an undercomplete autoencoder, the output of $f$ is smaller than the the input, so that the autoencoder learns to compress and decompress data.\n",
    "\n",
    "In this notebook you will implement an undercomplete autoencoder and train it on the Frey dataset which contains about 2,000 faces of a single person's face with different poses and expressions.  Then you will explore how well the autoencoder can compress and decompress data, synthesize new data, and interpolate between faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "92hXJ1pXnXoS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.rc('image', cmap='gray')\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2gXGvhZ5UNbj"
   },
   "source": [
    "## Data loading and pre-processing\n",
    "\n",
    "Here we download and unpack the Frey dataset.  The dataset consists of grayscale images, 28 pixels high and 20 pixels wide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2KYtbT-_s8IN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://cs.nyu.edu/~roweis/data/frey_rawface.mat\n",
      "1105920/1100584 [==============================] - 1s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import get_file\n",
    "from scipy.io import loadmat\n",
    "\n",
    "path = get_file('frey_rawface.mat','https://cs.nyu.edu/~roweis/data/frey_rawface.mat')\n",
    "data = np.transpose(loadmat(path)['ff'])\n",
    "images = np.reshape(data,(-1,28,20))\n",
    "np.random.shuffle(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DeCK7U-stU4V"
   },
   "outputs": [],
   "source": [
    "print(images.shape)\n",
    "for i in range(5):\n",
    "  plt.subplot(1,5,i+1)\n",
    "  plt.imshow(images[i])\n",
    "  plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eIOBVr6kUeXE"
   },
   "source": [
    "We split the data into training and testing splits (the data was shuffled above) and then convert to floating point on [-1 1] range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "alNXqRlrtoxG"
   },
   "outputs": [],
   "source": [
    "x_train = images[0:1800]\n",
    "x_test = images[1800:]\n",
    "x_train = (x_train.astype('float32')/255.)*2-1\n",
    "x_test = (x_test.astype('float32')/255.)*2-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tWqSOmXoUnr7"
   },
   "source": [
    "## Model implementation and training\n",
    "\n",
    "The code to build a linear autoencoder is given here.  Modify it to have multiple hidden layers with ReLU activation in the encoder and decoder.\n",
    "\n",
    "### Encoder:\n",
    "* Dense with 512 hidden units, ReLU activation\n",
    "* Dense with 512 hidden units, ReLU activation\n",
    "* Dense with 2 hidden units, tanh activation\n",
    "\n",
    "### Decoder:\n",
    "* Dense with 512 hidden units, ReLU activation\n",
    "* Dense with 512 hidden units, ReLU activation\n",
    "* Dense with 28*20 hidden units, linear activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dFgiO2UJuLpg"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Flatten, Dense, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "class Autoencoder:\n",
    "  def __init__(self):\n",
    "    self.encoder_layer = Dense(32,activation=None,name='encoder')\n",
    "    self.decoder_layer = Dense(28*20,activation=None,name='decoder')\n",
    "  \n",
    "  def get_autoencoder(self):\n",
    "    \"\"\" Builds the full autoencoder model with encoder and decoder. \"\"\"\n",
    "    inputs = Input((28,20),name='autoencoder_input')\n",
    "    x = Flatten()(inputs)\n",
    "    x = self.encoder_layer(x)\n",
    "    x = self.decoder_layer(x)\n",
    "    outputs = Reshape((28,20))(x)\n",
    "    return Model(inputs=inputs,outputs=outputs)\n",
    "  \n",
    "  def get_encoder(self):\n",
    "    \"\"\" Builds just the encoder model. \"\"\"\n",
    "    inputs = Input((28,20),name='encoder_input')\n",
    "    x = Flatten()(inputs)\n",
    "    x = self.encoder_layer(x)\n",
    "    return Model(inputs=inputs,outputs=x)\n",
    "  \n",
    "  def get_decoder(self):\n",
    "    \"\"\" Builds just the decoder model. \"\"\"\n",
    "    embedding = Input((32,),name='decoder_input')\n",
    "    x = embedding\n",
    "    x = self.decoder_layer(x)\n",
    "    outputs = Reshape((28,20))(x)\n",
    "    return Model(inputs=embedding,outputs=outputs)\n",
    "\n",
    "autoencoder = Autoencoder()\n",
    "\n",
    "ae_model = autoencoder.get_autoencoder()\n",
    "encoder_model = autoencoder.get_encoder()\n",
    "decoder_model = autoencoder.get_decoder()\n",
    "\n",
    "ae_model.compile(SGD(0.01,momentum=0.9),loss='mean_absolute_error')\n",
    "print(ae_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kJ45i6mXvGps"
   },
   "outputs": [],
   "source": [
    "history = ae_model.fit(x_train,x_train,batch_size=32,epochs=1000,verbose=False,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P9FvSz1KvNO9"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FUZVkUU63r7q"
   },
   "source": [
    "## Exercises\n",
    "\n",
    "*Before doing any of these exercises, make sure to modify the model as described above.*\n",
    "\n",
    "* Test the ability of the autoencoder to compress and decompress the images.  Compare some input images to their reconstructions after running the autoencoder.  What effect does the autoencoder have on the images?\n",
    "* VIsualize the output of the encoder (run on the training data) as a scatter plot.  Give some observations about the output.  Does it seem to be using all of the possible output space?\n",
    "* Generate new faces by making a grid of embedding points on $[-1~1]\\times[-1~1]$ (see code below).  Give some observations about the resulting images.\n",
    "* Test interpolation between two images (see the example from the autoencoder notebook).  Give some observations about the output.\n",
    "* Set up another autoencoder and train it on the spiral data from HW1.1. Visualize the embedding that it produces.  Does it produce an embedding where the separate spirals are linearly separable?  Does the autoencoder learn to map the spirals to tight, separated clusters?  (You might want to use linear activation rather than tanh for the encoder output in this part.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0wkTxRrd5YWj"
   },
   "source": [
    "This code makes a 10x10 grid of points from -1 to 1 in each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kavYBKCEaPFy"
   },
   "outputs": [],
   "source": [
    "coords = np.linspace(-1,1,num=10)\n",
    "x,y = np.meshgrid(coords,coords,indexing='xy')\n",
    "embeddings = np.stack([x.flatten(),y.flatten()],axis=1)\n",
    "plt.scatter(embeddings[:,0],embeddings[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "789Q7J_w5icv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "undercomplete_autoencoder.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
